{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVOOrCqxn721"
   },
   "source": [
    "## Week - 4 Assignment : Regression , Classification , Over fitting, Underfitting and Evaluation Metrics\n",
    "\n",
    "Due Date : 24 Feb 2023 11:59 PM (EST)\n",
    "\n",
    "## **Overview**\n",
    "In this assignment, you'll complete two parts in order:\n",
    "-   First, complete some analysis tasks(subjective questions) in this notebook.\n",
    "-  Second, complete several coding tasks, writing python code based on the instructions. You'll submit this python notebook separately.\n",
    "\n",
    "## **Background**\n",
    "\n",
    "To complete this assignment, you'll need to know the following:\n",
    "-   Python (NumPy, Pandas, Matplotlib, Scikit-learn)\n",
    "-   Linear Algebra\n",
    "-   Calculus\n",
    "-   Probability and Statistics\n",
    "-   Regression and Classification Models\n",
    "\n",
    "## **Tutorial**\n",
    "\n",
    "In case you are unfamiliar with the Python data ecosystem (NumPy, Pandas,scikit-learn), you are recommended to study the\n",
    "first four chapters of the Python data science handbook. You can find the book here: [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "\n",
    "## **Reference**\n",
    "\n",
    "-   [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "- Speech and Language Processing (3rd ed. draft) - [Chapter 4](https://web.stanford.edu/~jurafsky/slp3/4.pdf)\n",
    "- Speech and Language Processing (3rd ed. draft) - [Chapter 5](https://web.stanford.edu/~jurafsky/slp3/5.pdf)\n",
    "\n",
    "\n",
    "## **Submission**\n",
    "\n",
    "You will submit this notebook to ELMS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUpmal9Bn722"
   },
   "source": [
    "### Theory Task 1: Overfitting and Underfitting\n",
    "\n",
    "\n",
    "\n",
    "View the [image](https://drive.google.com/file/d/1QCXgJZ-vWtzmaAJqsM18TGHCMZw0HzQj/view)\n",
    "\n",
    "![any name you like](https://drive.google.com/uc?export=view&id=1QCXgJZ-vWtzmaAJqsM18TGHCMZw0HzQj)\n",
    "\n",
    "\n",
    "**Question 1.1** In the above figure, Does the model suffer from underfitting or overfitting? Why? How can you improve the model?\n",
    "\n",
    "Ans)The model suffers from overfitting. This is due to the fact that the training loss goes down over time while the validation loss goes down until a turning point is found and then increases again. This turning point implies the beginning of overfitting.\n",
    "\n",
    "Also, from the accuracy graph, we can see the training accuracy keeps increasing while our validation accuracy does not increase anymore after a point.\n",
    "\n",
    "We can improve this model by:\n",
    "a)Increasing the training data by data augmentation\n",
    "b)Feature selection by choosing the best features and removing the unnecessary features\n",
    "c)Reducing the complexity of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgjVJnN3n723"
   },
   "source": [
    "### Theory Task 2 :  Evaluation Metrics\n",
    "\n",
    "**Question 2.1** Suppose you are building a model to predict whether a person has a rare disease that only affects 1% of the population. You have collected a dataset of 10,000 people, of which only 100 have the disease. You train your model and get an accuracy of 99%, which seems very high. However, you are concerned that the model may not be performing well on the minority class. What evaluation metric would you use to assess the model's performance, and why?\n",
    "\n",
    "Ans) I would use Recall, i.e., (TP/(TP+FN)). This is because it will help me in knowing whether the minority class were properly identified or not when I am able to get the actual positives from the data.\n",
    "Accuracy would not help me if the data is actually imbalanced and would not perform well for the minority class. Precision focuses on false positives as well which will not help me get the right data for deciding."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "7Bj2kDTFn724"
   },
   "source": [
    "**Question 2.2** What evaluation metric would be most appropriate for a machine learning model that is used to screen patients for a certain disease in order to refer them for further testing, and why? Would you use precision or recall as the primary evaluation metric for this problem, and why?\n",
    "\n",
    "Ans)Recall, since we would have fewer undetected patients as compared to not detecting a patient's disease in Precision. This may cause non-diseased patients on being treated as a diseased patient but they can also go for further testing which I feel is not a bad thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uW_Vt0pdn724"
   },
   "source": [
    "**Question 2.3** Given a dataset of medical records, including age, gender, blood pressure, cholesterol level, and heart disease diagnosis (yes/no), which classification algorithm - logistic regression or naive Bayes - would you choose to predict whether a new patient is likely to have heart disease or not, and why? The dataset has 1000 samples with a class distribution of 30% positive and 70% negative, and a total of 5 features.\n",
    "\n",
    "Ans) I would pick Logistic Regression. Logistic regression with linearization can work with large datasets better than Naive Bayes and also, Logistic regression performs better than Naive Bayes upon colinearity, as naive bayes expects all features to be independent, but most features are dependent on each other for heart disease diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOdiIu51n724"
   },
   "source": [
    "## Coding Task 1 : Dataset Exploration\n",
    "\n",
    "In this task, you will explore the dataset, clean it, and perform some basic analysis. You will use the cars dataset which contains about the price of cars and some of their features. The dataset is available in the file `car_dataset.csv`. The dataset contains the following columns:\n",
    "\n",
    "-   `price`: the price of the car\n",
    "-   `year`: the year in which the car was manufactured\n",
    "-   `mileage`: the number of miles the car has been driven\n",
    "-   `state`: the state in which the car is being sold\n",
    "-   `make`: the make of the car\n",
    "-   `model`: the model of the car\n",
    "-   `engine`: the engine capacity of the car\n",
    "-   `transmission`: the type of transmission the car has\n",
    "-   `fuel`: the type of fuel the car uses\n",
    "-   `seats`: the number of seats in the car\n",
    "-   `seller_type`: the type of seller\n",
    "-   `price_category`: the price category of the car\n",
    "\n",
    "- The target variable is `price_category` which is a categorical variable with three possible values: `low`, `medium`, and `high`. The `price_category` column is the column you will try to predict using the other columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Rylw7eAn724"
   },
   "source": [
    "### **Data Loading and Tranformation**\n",
    "- Load the dataset from the file \"car_dataset.csv\" into a pandas dataframe.\n",
    "- Display the first 5 rows of the dataframe to ensure it has loaded correctly.\n",
    "- Explore the dataset using descriptive statistics like mean, median, mode, standard deviation, and range.\n",
    "- Check if there are any missing values in the dataset and handle them based on the column and data type. For example, you could choose to remove rows with missing values or fill in the missing values with appropriate values like the mean or mode.\n",
    "- Remove the units from the numerical columns and convert them to the appropriate data type. For example, the `mileage` column has the unit \"miles\" and the `engine` column has the unit \"cc\". You should remove the units and convert the columns to the appropriate data type.\n",
    "- Check for categorical features and convert them into numerical values, as most machine learning algorithms work with numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AOqcsQEn725"
   },
   "source": [
    "## Coding Task 2: Data Visualization\n",
    "### **Subsection 1: Correlation**\n",
    "\n",
    "- Compute the correlation matrix using the corr() method from the pandas library.\n",
    "- Visualize the correlation matrix using a heatmap created with the heatmap() method from the seaborn library.\n",
    "    - Hints: Identify variables that have high correlation with the target variable, and variables that have high correlation with each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2Tfm-wbn725"
   },
   "source": [
    "### **Subsection 2: Feature Analysis**\n",
    "\n",
    "- Create scatter plots to visualize the relationship between the variables that have positive and negative correlation identified in the previous step.\n",
    "- Create barplots for each categorical feature to check for class imbalance.\n",
    "- Check for outliers in the data using boxplots.\n",
    "    - Hints: \n",
    "        - 1.Identify any outliers in the data, and determine if any features have a skewed distribution or class imbalance.\n",
    "        - 2.Look for patterns and relationships between variables, and identify any variables that may be good predictors for the target variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igOHQXy-n725"
   },
   "source": [
    "### **Subsection 3: Feature Selection**\n",
    "- Identify the relevant features in the dataset that may affect the price of the car. You can use domain knowledge or explore the relationship between the different columns and the target column.\n",
    "- Remove any irrelevant features that are not required for the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PHgOZZXn725"
   },
   "source": [
    "### **Subsection 4: Standardization**\n",
    "- Standardize the remaining features in the dataset so that they have zero mean and unit variance. This will help in improving the performance of the machine learning algorithms.\n",
    "- Use the StandardScaler class from the sklearn.preprocessing module to perform standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq40rHgAn725"
   },
   "source": [
    "### **Subsection 5: Data Splitting**\n",
    "- Split the dataset into training and testing sets. The training set is used to train the machine learning model, and the testing set is used to evaluate its performance.\n",
    "- Use the train_test_split() function from the sklearn.model_selection module to split the dataset.\n",
    "- Ensure that the split is random and stratified, so that the distribution of classes in the training and testing sets is similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TLqXdZan725"
   },
   "source": [
    "\n",
    "## Coding Task 3 : Model Training and Evaluation\n",
    "\n",
    "In this task, you will train a machine learning model to predict the price category of a car based on its features. You will use the training set to train the model, and the testing set to evaluate its performance.\n",
    "\n",
    "### **Subsection 1: Model Training**\n",
    "- Train a logistic regression model on the training set.\n",
    "- Use the LogisticRegression class from the sklearn.linear_model module to train the model.\n",
    "- Use the default parameters for the model.\n",
    "- Use the training set to train the model.\n",
    "- Use the predict() method to make predictions on the testing set.\n",
    "- Use the accuracy_score() function from the sklearn.metrics module to evaluate the model's performance on the testing set.\n",
    "\n",
    "### **Subsection 2: Model Evaluation**\n",
    "- Use the confusion matrix to evaluate the model's performance on the testing set.\n",
    "- Use the classification_report() function from the sklearn.metrics module to evaluate the model's performance on the testing set.\n",
    "- Use the roc_auc_score() function from the sklearn.metrics module to evaluate the model's performance on the testing set.\n",
    "\n",
    "### **Subsection 3: Model Tuning (Optional)**\n",
    " \n",
    "- Tune the model to improve its performance.\n",
    "- Use the GridSearchCV class from the sklearn.model_selection module to tune the model.\n",
    "- Use the following parameters for the model:\n",
    "    - penalty: l1, l2 ( Regularization penalty term )\n",
    "    - C: 0.1, 0.5, 1, 2, 5 ( Inverse of regularization strength )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a40522a8eb7aacb1bd29b236cac1d994c6cb7aaf249904f7446f2c7da9d8006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
